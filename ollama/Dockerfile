# k8s/ollama/Dockerfile

# Use the Ollama image with GPU support
FROM ollama/ollama

# Expose the Ollama default port
EXPOSE 11434

# Start Ollama server by default
CMD ["ollama", "serve"]